{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TFRecord and tf.SequenceExample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If your dataset consists of features where each feature is a list of values of the same type, the [`tf.train.Example`](https://www.tensorflow.org/api_docs/python/tf/train/Example) proto message is a great choice for storing your data.\n",
        "However, this message format has some shortcomings when it comes to dealing with features that consists of lists of identically typed data. That is because, in TensorFlow, [`tf.train.Example`](https://www.tensorflow.org/api_docs/python/tf/train/Example) protos are read in row-major format, so any configuration that describes data with rank-2 or above is harder to represent.\n",
        "\n",
        "For example, to store an `M x N` matrix of Bytes, the [`tf.train.BytesList`](https://www.tensorflow.org/api_docs/python/tf/train/BytesList) must contain `M * N` bytes, with `M` rows of `N` contiguous values each. That is, the [`tf.train.BytesList`](https://www.tensorflow.org/api_docs/python/tf/train/BytesList) value must store the matrix as:\n",
        "\n",
        "```\n",
        "    .... row 0 .... .... row 1 .... // ...........  // ... row M-1 ....\n",
        "```\n",
        "\n",
        "As you can see, this is not ideal. A more elegant approach would be to use [`tf.train.SequenceExample`](https://www.tensorflow.org/api_docs/python/tf/train/SequenceExample)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "While a `tf.train.Example` is fundamentally a mapping from feature names to `tf.train.Feature`, a `tf.train.SequenceExample` extends this data structure by adding a second mapping from feature names to [`tf.train.FeatureList`](https://www.tensorflow.org/api_docs/python/tf/train/FeatureList).\n",
        "\n",
        "A `tf.train.FeatureList` is practically a container for sequential data, as it contains lists of `tf.train.Feature`. And here lies the key: if you need to use __lists of lists__, it's better to use `tf.train.SequenceExample`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook will demonstrate how to create, parse and use the [`tf.train.SequenceExample`](https://www.tensorflow.org/api_docs/python/tf/train/SequenceExample) message, and then serialize, write, and read [`tf.train.SequenceExample`](https://www.tensorflow.org/api_docs/python/tf/train/SequenceExample) messages to and from `.tfrecord` files. \n",
        "\n",
        "Note: [`tf.train.Example`](https://www.tensorflow.org/api_docs/python/tf/train/Example) is very generic and can be used to represent any sort of data. While not providing any extra power, [`tf.train.SequenceExample`](https://www.tensorflow.org/api_docs/python/tf/train/SequenceExample) offers a little more structure to your data and it is more pleasant to work with it in certain scenarios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating a `tf.train.SequenceExample`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To create a `tf.train.SequenceExample` you generally have to take care of:\n",
        "* Context-level values:\n",
        "    1. each context-level value needs to be converted to a `tf.train.Feature` containing one of the 3 compatible types (`tf.train.BytesList`, a `tf.train.FloatList` or a `tf.train.Int64List`)\n",
        "    2. create a map from the context-level feature name string to the encoded feature value produced in the previous step\n",
        "    3. the map produced in step 2 is converted to a [`Features` message](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/feature.proto#L85).\n",
        "* Sequences of values:\n",
        "    1. for each sequence, create a list of `tf.train.Feature` messages by converting every value in the sequence to a `tf.train.Feature`\n",
        "    2. the lists produced in the previous step are used create `tf.train.FeatureList` messages\n",
        "    3. create a map from the sequence feature name string to the corresponding `tf.train.FeatureList` produces in step 2\n",
        "    4. the map produced in step 3 is converted to a [`FeatureLists` message](https://www.tensorflow.org/api_docs/python/tf/train/FeatureLists)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this notebook, you will create `tf.train.SequenceExample` messages from JSON records.\n",
        "\n",
        "The records represent sentences as they are ingested by an NLP model and each sentence has the following features:\n",
        "- 2 context-level features:\n",
        "    - the length of the sentence, an integer, representing the number of tokens\n",
        "    - the sentiment of the sentence, either `negative`, `neutral` or `positive`, as strings\n",
        "- 2 sequence features:\n",
        "    - the raw values of the words in the sentence, as strings\n",
        "    - [BIO tags](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)), as strings, to indicate if the corresponding word is part of a named entity (in this case an academic institution name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "sentences_json = '[ \\\n",
        "    { \\\n",
        "        \"sentiment\": \"positive\", \\\n",
        "        \"length\": 14, \\\n",
        "        \"words\": [ \\\n",
        "            { \"value\": \"The\",         \"ner-tag\": \"B-inst\"}, \\\n",
        "            { \"value\": \"University\",  \"ner-tag\": \"I-inst\"}, \\\n",
        "            { \"value\": \"of\",          \"ner-tag\": \"I-inst\"}, \\\n",
        "            { \"value\": \"Manchester\",  \"ner-tag\": \"I-inst\"}, \\\n",
        "            { \"value\": \"is\",          \"ner-tag\": \"O\"}, \\\n",
        "            { \"value\": \"a\",           \"ner-tag\": \"O\"}, \\\n",
        "            { \"value\": \"leading\",     \"ner-tag\": \"O\"}, \\\n",
        "            { \"value\": \"academic\",    \"ner-tag\": \"O\"}, \\\n",
        "            { \"value\": \"institution\", \"ner-tag\": \"O\"}, \\\n",
        "            { \"value\": \"in\",          \"ner-tag\": \"O\"}, \\\n",
        "            { \"value\": \"the\",         \"ner-tag\": \"O\"}, \\\n",
        "            { \"value\": \"United\",      \"ner-tag\": \"O\"}, \\\n",
        "            { \"value\": \"Kingdom\",     \"ner-tag\": \"O\"}, \\\n",
        "            { \"value\": \".\",           \"ner-tag\": \"O\"} \\\n",
        "        ] \\\n",
        "    } \\\n",
        "]'\n",
        "\n",
        "sentences = json.loads(sentences_json)\n",
        "sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To convert our values, we can define some helper functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The context-level features can be converted directly to `tf.train.Feature` using the helper functions and then a `tf.train.Features` message can be created:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_context_features(sentence):\n",
        "    return tf.train.Features(feature={\n",
        "        'length': _int64_feature(sentence['length']),\n",
        "        'sentiment': _bytes_feature(sentence['sentiment'].encode('utf-8')) # get the bytes of the string using .encode()\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The sequences need to be collated first into lists, and then the latter can be converted to `tf.train.FeatureList`. Finally, using the `tf.train.FeatureList` protos, you can create the `tf.train.FeatureLists`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_sequence_features(sentence):\n",
        "    word_features = []\n",
        "    bio_tag_features = []\n",
        "    \n",
        "    for word in sentence['words']:\n",
        "        # create each of the features, then add them to the corresponding feature list\n",
        "        word_feature = _bytes_feature(word['value'].encode('utf-8'))\n",
        "        word_features.append(word_feature)\n",
        "        \n",
        "        bio_tag_feature = _bytes_feature(word['ner-tag'].encode('utf-8'))\n",
        "        bio_tag_features.append(bio_tag_feature)\n",
        "        \n",
        "    words = tf.train.FeatureList(feature=word_features)\n",
        "    bio_tags = tf.train.FeatureList(feature=bio_tag_features)\n",
        "    \n",
        "    return tf.train.FeatureLists(feature_list={\n",
        "        'words': words,\n",
        "        'bio-tags': bio_tags\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once we have the `tf.train.Features` and `tf.train.FeatureLists` messages, we can create the `tf.train.SequenceExample` message:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_sequence_example(sentence):\n",
        "    context_features = create_context_features(sentence)\n",
        "    sequence_features = create_sequence_features(sentence)\n",
        "    \n",
        "    return tf.train.SequenceExample(\n",
        "        context = context_features,\n",
        "        feature_lists = sequence_features\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now serialiaze our sentences to prepare them for being written in `.tfrecord` files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "serialized_sequence_example = make_sequence_example(sentences[0]).SerializeToString()\n",
        "serialized_sequence_example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To decode it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "example_proto = tf.train.SequenceExample.FromString(serialized_sequence_example)\n",
        "example_proto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Writing to TFRecord files using Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is exactly the same as writing `tf.train.Example` messages. The `tf.io` module contains pure-Python functions for reading and writing TFRecord files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filename = 'test.tfrecord'\n",
        "\n",
        "with tf.io.TFRecordWriter(filename) as writer:\n",
        "    for sentence in sentences:\n",
        "        seq_example = make_sequence_example(sentence).SerializeToString()\n",
        "        writer.write(seq_example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reading it back:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filenames = [filename]\n",
        "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
        "raw_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: iterating over a `tf.data.Dataset` only works with eager execution enabled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# call tf.enable_eager_execution() - must be enabled at program startup\n",
        "\n",
        "for raw_record in raw_dataset.take(1):\n",
        "  print(repr(raw_record))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "seq_example.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
